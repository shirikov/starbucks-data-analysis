{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# load data\n",
    "offer_data = pd.read_csv('data/cleaned_offer_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook documents an analysis of the probability of completing various promotional offers based on Starbucks data. The notebook uses a cleaned data set on offers received by each user that was created in a separate notebook (starbucks_data_cleanup.ipynb).\n",
    "\n",
    "The overall idea for the analysis is to use a machine learning algorithm to predict whether users complete (redeem) the offers from existing data on users and offers. We can then use models with sufficient predictive power to compare predicted probabilities of completing the offers for different segments of customers or for offers with different characteristics. In this analysis, we will mainly use logistic regression, as it usually performs well with respect to binary predictions, and it also allows us to examine the contribution of each predictor by looking at regression coefficients. We will also look at who is more likely to view offers using the same model setup.\n",
    "\n",
    "At the end of the analysis, there is a discussion of the takeaways and possible improvements.\n",
    "\n",
    "# Setting Up\n",
    "\n",
    "First, we create several dummy variables for segments of the customer base based on age, income, gender, and when one became a member. As for age, standard age group ranges (0--20, 21--30, etc.) were used. Incomes in the data set were in the range from 30,000 to 120,000, so 20K brackets were used except for the first one (0--40). Membership duration was split into five bins: 0-3 months, 4-6 months, 7-12 months, 1-2 years, more than 2 years. We also add dummies for offer types: BOGO, discount, and informational (informational offers will not be used in this analysis as they cannot be 'completed')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn continuous variables to categorical\n",
    "offer_data['age_group'] = pd.cut(\n",
    "    offer_data.age, bins=[0, 20, 30, 40, 50, 60, 150],\n",
    "    labels=['18-20', '21-30', '31-40', '41-50', '51-60', '61+'])\n",
    "offer_data['income_group'] = pd.cut(\n",
    "    offer_data.income, bins=[0, 40000, 60000, 80000, 100000, 120000],\n",
    "    labels=['0-40K', '41-60K', '61-80K', '81-100K', '101-120K'])\n",
    "offer_data['member_months_group'] = pd.cut(\n",
    "    offer_data.member_months, bins=[0, 3, 6, 12, 24, 1000],\n",
    "    labels=['0-3 months', '4-6 months', '7-12 months', \n",
    "            '1-2 years', '2+ years'])\n",
    "\n",
    "# recode offer ids\n",
    "offer_data['offer_id_alt'] = (offer_data.offer_type + ' ') + (\n",
    "    offer_data.offer_reward.astype(str) + ' (') + (\n",
    "        (offer_data.offer_duration/24).astype(int).astype(str) + ' days)')\n",
    "        \n",
    "# drop informational offers\n",
    "offer_data = offer_data[offer_data.offer_type != 'informational']\n",
    "\n",
    "# create dummies\n",
    "offer_data = pd.concat([offer_data,\n",
    "                            pd.get_dummies(offer_data['age_group'],\n",
    "                                           prefix='Age'),\n",
    "                            pd.get_dummies(offer_data['income_group'],\n",
    "                                           prefix='Income'),\n",
    "                            pd.get_dummies(offer_data['gender'],\n",
    "                                           prefix='Gender'),\n",
    "                            pd.get_dummies(offer_data['member_months_group'], \n",
    "                                           prefix='Member'),\n",
    "                            pd.get_dummies(offer_data['offer_type'], \n",
    "                                           prefix='Type'),\n",
    "                            pd.get_dummies(offer_data['offer_id_alt'], \n",
    "                                           prefix='Offer')],\n",
    "                            axis=1)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up functions to split the data into train and test sets and to fit the models.\n",
    "\n",
    "In this case, instead of using the standard train_test_split function, it is reasonable to split the data into train and test sets at the level of the user. For this purpose, we use a custom splitting function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_user(X, y):\n",
    "    \n",
    "    '''\n",
    "    Create a train and test list of user ids, then split the data accordingly.\n",
    "    \n",
    "    Args:\n",
    "        X: a data frame of predictors\n",
    "        y: the target variable (pandas series)\n",
    "    '''\n",
    "    \n",
    "    # create train and test sets of users\n",
    "    train_ix, test_ix = next(gss.split(X, y, groups=X.user_id))\n",
    "    \n",
    "    # split into train and test\n",
    "    X = X.drop(columns='user_id')\n",
    "    X_train = X.iloc[train_ix]\n",
    "    y_train = y.iloc[train_ix]\n",
    "    X_test = X.iloc[test_ix]\n",
    "    y_test = y.iloc[test_ix]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# initialize the command for splitting the data\n",
    "gss = GroupShuffleSplit(n_splits=2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function fits the models, outputs model evaluation, and, in case of logistic regression models, saves the regression coefficients for the subsequent interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_test(model_pipeline, return_coefs=False):\n",
    "    \n",
    "    '''\n",
    "    Fit the model, print out model evaluations on test data,\n",
    "    return coefficients.\n",
    "    \n",
    "    Args:\n",
    "        model_pipeline: a pipeline/a model object\n",
    "    '''\n",
    "    \n",
    "    # Fit the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    \n",
    "    print('F1 score:')\n",
    "    print(round(f1_score(y_test, y_pred), 3))\n",
    "    print('Precision:')\n",
    "    print(round(precision_score(y_test, y_pred), 3))\n",
    "    print('Recall:')\n",
    "    print(round(recall_score(y_test, y_pred), 3))\n",
    "    \n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    ConfusionMatrixDisplay.from_estimator(model_pipeline, X_test, y_test, \n",
    "                                          normalize='all')\n",
    "    \n",
    "    if return_coefs:\n",
    "        coefs = pd.DataFrame({'var': X_train.columns.tolist(),\n",
    "                              'coef': model_pipeline.named_steps[\n",
    "                              'logit'].coef_.flatten()})\n",
    "        return coefs\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we set up two model pipelines, one using logistic regression, and another using gradient boosting. In both cases, data are normalized using a MinMaxScaler from sklearn, which rescales each variable to take values from 0 to 1. This is more appropriate in this case compared to standard centering and scaling because many of the variables are dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model pipelines\n",
    "pipeline_logit = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('logit', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline_boost = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('boost', GradientBoostingClassifier(max_depth=1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the analysis below, we will use the following set of predictors:\n",
    "- Dummies for promo campaigns (offers). While the data contain several characteristics for each offer, such as its type, reward, duration, and required spending, there are just 8 offers in this analysis (after dropping 2 informational ones), and including all these specific characteristics will be essentially the same as including just the offer ids, as the set of these features allows to identify each offer precisely (see the list of offers below). It would thus be easier to interpret the results if we include just the dummies for each offer. The dummy 'bogo 5 (5 days)' is omitted and serves as the reference category.\n",
    "- The count of previously completed offers by the same user (one variable counts offers with the same id, the other variable counts all previously completed offers). This allows us to capture whether one tends to spend more or to seek offers more actively.\n",
    "- Age groups. The group 'Age 18-20' serves as a reference category.\n",
    "- Income groups. The group '0-40K' serves as a reference category.\n",
    "- How long one has been a member. '0-3 months' is a reference category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offers in the analysis (the number after offer type is reward value in dollars):\n",
      "['bogo 10 (5 days)', 'bogo 10 (7 days)', 'bogo 5 (5 days)', 'bogo 5 (7 days)', 'discount 2 (10 days)', 'discount 2 (7 days)', 'discount 3 (7 days)', 'discount 5 (10 days)']\n"
     ]
    }
   ],
   "source": [
    "print('Offers in the analysis (the number after offer type is reward value in dollars):')\n",
    "print(offer_data.sort_values('offer_id_alt').offer_id_alt.unique().tolist())\n",
    "\n",
    "x_vars = ['Offer_bogo 10 (5 days)', 'Offer_bogo 10 (7 days)', \n",
    "          'Offer_bogo 5 (7 days)',\n",
    "          'Offer_discount 2 (7 days)',  'Offer_discount 2 (10 days)',\n",
    "          'Offer_discount 3 (7 days)', 'Offer_discount 5 (10 days)', \n",
    "          'same_offer_completed_before', 'any_offer_completed_before',\n",
    "          'Age_21-30', 'Age_31-40', 'Age_41-50', 'Age_51-60', 'Age_61+',\n",
    "          'Income_41-60K', 'Income_61-80K', 'Income_81-100K', \n",
    "          'Income_101-120K', \n",
    "          'Gender_Female', 'Gender_Other', \n",
    "          'Member_4-6 months', 'Member_7-12 months',\n",
    "          'Member_1-2 years', 'Member_2+ years']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a matrix of predictors X and the outcome variable, and then we split the data into the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y\n",
    "offer_data_X = offer_data[['user_id'] + x_vars]\n",
    "offer_data_y = offer_data['completed']\n",
    "\n",
    "# train and test\n",
    "X_train, y_train, X_test, y_test = train_test_split_by_user(offer_data_X,\n",
    "                                                            offer_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Finding the Best-Performing Model\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "The logistic regression implementation in sklearn by default includes a regularization penalty, but the strength of regularization could be tuned via the parameter called C. First, we use grid search with cross-validation to find the optimal value of C.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:\n",
      "0.799\n",
      "Precision:\n",
      "0.774\n",
      "Recall:\n",
      "0.826\n",
      "Confusion matrix:\n",
      "[[3557 2401]\n",
      " [1733 8221]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grid search for optimal model parameters\n",
    "parameters_logit = {\n",
    "        'logit__C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000]\n",
    "    }\n",
    "logit_cv = GridSearchCV(pipeline_logit, param_grid=parameters_logit)\n",
    "fit_test(logit_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model has an F1 score of 0.8, which is pretty good. EXPLAIN F1 SCORE AND TALK ABT PRECISION/RECALL, PRECISION SOMEWHAT LOWER THAN RECALL.\n",
    "\n",
    "The optimal value of C is 10, as shown below, so this is what we will use going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameter: {'logit__C': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Optimal parameter: ' + str(logit_cv.best_params_))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63988c7776bd4b2216d881fd2ad90ced5e2987f9f8c410eebe313e5d7f3b1f68"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
